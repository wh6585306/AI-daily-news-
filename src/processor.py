"""
LLMæ™ºèƒ½å¤„ç†æ¨¡å— - å¢å¼ºç‰ˆ
åŒ…å«å½±å“åŠ›è¯„ä¼°æ¨¡å‹ï¼Œæ”¯æŒ100+åŸå§‹ä¿¡æ¯å¤„ç†ï¼Œè¾“å‡º5-20æ¡ç²¾é€‰æ–°é—»
"""
import json
import os
import sys
import re
from datetime import datetime
from typing import List, Dict, Any, Optional, Tuple
from openai import OpenAI

sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from config import (
    OPENAI_API_KEY, OPENAI_BASE_URL, OPENAI_MODEL,
    MIN_NEWS_PER_CATEGORY, MAX_NEWS_PER_CATEGORY,
    IMPACT_KEYWORDS, SOURCE_WEIGHTS
)


class ImpactScorer:
    """
    å½±å“åŠ›è¯„ä¼°æ¨¡å‹
    åŸºäºå…³é”®è¯æƒé‡ã€æ¥æºæƒé‡å’Œå†…å®¹åˆ†æè¿›è¡Œç»¼åˆè¯„åˆ†
    """
    
    def __init__(self):
        self.impact_keywords = IMPACT_KEYWORDS
        self.source_weights = SOURCE_WEIGHTS
    
    def calculate_score(self, news: Dict) -> Tuple[float, str, List[str]]:
        """
        è®¡ç®—æ–°é—»çš„å½±å“åŠ›è¯„åˆ†
        è¿”å›: (åˆ†æ•°, é‡è¦æ€§ç­‰çº§, åŒ¹é…çš„æ ‡ç­¾)
        """
        title = news.get("title", "").lower()
        summary = news.get("summary", "").lower()
        source = news.get("source", "")
        content = f"{title} {summary}"
        
        base_score = 0
        matched_tags = []
        category_scores = {}
        
        # 1. å…³é”®è¯åŒ¹é…è®¡åˆ†
        for category, config in self.impact_keywords.items():
            weight = config["weight"]
            keywords = config["keywords"]
            
            for keyword in keywords:
                if keyword.lower() in content:
                    if category not in category_scores:
                        category_scores[category] = 0
                    category_scores[category] += weight
                    matched_tags.append(keyword)
        
        # å–æœ€é«˜ç±»åˆ«åˆ†æ•°ä½œä¸ºåŸºç¡€åˆ†
        if category_scores:
            base_score = max(category_scores.values())
        
        # 2. æ¥æºæƒé‡åŠ æˆ
        source_multiplier = 1.0
        for tier, config in self.source_weights.items():
            if source in config.get("sources", []):
                source_multiplier = config["multiplier"]
                break
        
        # 3. è®¡ç®—æœ€ç»ˆåˆ†æ•°
        final_score = base_score * source_multiplier
        
        # 4. é¢å¤–åŠ åˆ†è§„åˆ™
        # æ ‡é¢˜ä¸­åŒ…å«é‡è¦è¯æ±‡é¢å¤–åŠ åˆ†
        important_title_words = [
            "breaking", "exclusive", "official", "confirmed",
            "çªå‘", "ç‹¬å®¶", "å®˜å®£", "é‡ç£…", "é¦–å‘"
        ]
        for word in important_title_words:
            if word.lower() in title:
                final_score += 20
        
        # æ¶‰åŠå¤šä¸ªé‡è¦ä¸»é¢˜é¢å¤–åŠ åˆ†
        if len(category_scores) >= 2:
            final_score += 15 * (len(category_scores) - 1)
        
        # 5. ç¡®å®šé‡è¦æ€§ç­‰çº§
        importance = self._determine_importance(final_score)
        
        # å»é‡æ ‡ç­¾
        matched_tags = list(set(matched_tags))[:5]
        
        return final_score, importance, matched_tags
    
    def _determine_importance(self, score: float) -> str:
        """æ ¹æ®åˆ†æ•°ç¡®å®šé‡è¦æ€§ç­‰çº§"""
        if score >= 80:
            return "é«˜"
        elif score >= 40:
            return "ä¸­"
        else:
            return "ä½"
    
    def rank_news(self, news_list: List[Dict]) -> List[Dict]:
        """å¯¹æ–°é—»åˆ—è¡¨è¿›è¡Œæ’åºå’Œè¯„åˆ†"""
        scored_news = []
        
        for news in news_list:
            score, importance, tags = self.calculate_score(news)
            news_copy = news.copy()
            news_copy["impact_score"] = score
            news_copy["importance"] = importance
            news_copy["auto_tags"] = tags
            scored_news.append(news_copy)
        
        # æŒ‰åˆ†æ•°é™åºæ’åº
        scored_news.sort(key=lambda x: x["impact_score"], reverse=True)
        
        return scored_news


class NewsProcessor:
    """æ–°é—»å¤„ç†å™¨ - å¢å¼ºç‰ˆ"""
    
    def __init__(self):
        self.client = OpenAI(
            api_key=OPENAI_API_KEY,
            base_url=OPENAI_BASE_URL
        ) if OPENAI_API_KEY else None
        self.model = OPENAI_MODEL
        self.scorer = ImpactScorer()
    
    def process_news(self, raw_news: Dict[str, List[Dict]]) -> Dict[str, Any]:
        """å¤„ç†åŸå§‹æ–°é—»æ•°æ®ï¼ˆ100+æ¡ -> 5-20æ¡ç²¾é€‰ï¼‰"""
        today = datetime.now().strftime("%Y-%m-%d")
        month = datetime.now().month
        day = datetime.now().day
        
        # ç»Ÿè®¡åŸå§‹æ•°æ®
        raw_domestic_count = len(raw_news.get("domestic", []))
        raw_international_count = len(raw_news.get("international", []))
        total_raw = raw_domestic_count + raw_international_count
        
        print(f"\nğŸ“Š åŸå§‹æ•°æ®ç»Ÿè®¡:")
        print(f"   - å›½å†…åŸå§‹æ–°é—»: {raw_domestic_count} æ¡")
        print(f"   - å›½é™…åŸå§‹æ–°é—»: {raw_international_count} æ¡")
        print(f"   - æ€»è®¡: {total_raw} æ¡")
        
        result = {
            "date": today,
            "generated_at": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            "domestic": [],
            "international": [],
            "summary": "",
            "statistics": {
                "raw_domestic": raw_domestic_count,
                "raw_international": raw_international_count,
                "raw_total": total_raw
            }
        }
        
        # æ­¥éª¤1: å½±å“åŠ›è¯„åˆ†å’Œåˆæ­¥æ’åº
        print("\nğŸ¯ æ­¥éª¤1: å½±å“åŠ›è¯„åˆ†...")
        domestic_scored = self.scorer.rank_news(raw_news.get("domestic", []))
        international_scored = self.scorer.rank_news(raw_news.get("international", []))
        
        print(f"   - å›½å†…é«˜åˆ†æ–°é—»: {len([n for n in domestic_scored if n['importance'] == 'é«˜'])} æ¡")
        print(f"   - å›½é™…é«˜åˆ†æ–°é—»: {len([n for n in international_scored if n['importance'] == 'é«˜'])} æ¡")
        
        # æ­¥éª¤2: LLMç²¾ç»†å¤„ç†
        if self.client:
            print("\nğŸ¤– æ­¥éª¤2: LLMæ™ºèƒ½åˆ†æ...")
            result["domestic"] = self._process_with_llm(
                domestic_scored[:50],  # å–å‰50æ¡ç»™LLMå¤„ç†
                "å›½å†…"
            )
            result["international"] = self._process_with_llm(
                international_scored[:50],
                "å›½é™…"
            )
        else:
            print("\nâš ï¸ æ— LLMï¼Œä½¿ç”¨è§„åˆ™å¤„ç†...")
            result["domestic"] = self._rule_based_process(domestic_scored)
            result["international"] = self._rule_based_process(international_scored)
        
        # æ­¥éª¤3: ç¿»è¯‘å›½é™…æ–°é—»ä¸ºä¸­æ–‡
        print("\nğŸŒ æ­¥éª¤3: ç¿»è¯‘å›½é™…æ–°é—»...")
        result["international"] = self._translate_international_news(result["international"])
        
        # æ­¥éª¤4: ç”Ÿæˆç²¾ç®€ç‰ˆï¼ˆæ¯ç±»3-8æ¡ï¼‰
        print("\nğŸ“ æ­¥éª¤4: ç”Ÿæˆç²¾ç®€ç‰ˆ...")
        result["domestic_brief"] = self._generate_brief(result["domestic"], 5)
        result["international_brief"] = self._generate_brief(result["international"], 5)
        
        # æ­¥éª¤5: ç”Ÿæˆæ€»ç»“
        result["summary"] = self._generate_summary(result)
        
        # æ›´æ–°ç»Ÿè®¡
        result["statistics"]["final_domestic"] = len(result["domestic"])
        result["statistics"]["final_international"] = len(result["international"])
        
        return result
    
    def _translate_international_news(self, news_list: List[Dict]) -> List[Dict]:
        """ç¿»è¯‘å›½é™…æ–°é—»ä¸ºä¸­æ–‡"""
        if not news_list:
            return news_list
        
        today = datetime.now()
        month_day = f"{today.month}æœˆ{today.day}æ—¥"
        
        for news in news_list:
            summary = news.get("summary", "")
            # å¦‚æœæ˜¯è‹±æ–‡æ‘˜è¦ï¼Œå°è¯•ç”¨LLMç¿»è¯‘
            if self.client and summary and not self._is_chinese(summary):
                try:
                    translated = self._translate_with_llm(summary, month_day)
                    if translated:
                        news["summary"] = translated
                except:
                    # ç¿»è¯‘å¤±è´¥æ—¶ä¿æŒåŸæ–‡
                    pass
            # ç¡®ä¿æ ¼å¼æ­£ç¡®
            if not news.get("summary", "").startswith(f"{today.month}æœˆ"):
                news["summary"] = f"{month_day}æ¶ˆæ¯ï¼Œ{news.get('summary', '')}"
        
        return news_list
    
    def _is_chinese(self, text: str) -> bool:
        """æ£€æŸ¥æ–‡æœ¬æ˜¯å¦ä¸»è¦æ˜¯ä¸­æ–‡"""
        if not text:
            return False
        chinese_count = sum(1 for c in text if '\u4e00' <= c <= '\u9fff')
        return chinese_count > len(text) * 0.3
    
    def _translate_with_llm(self, text: str, month_day: str) -> str:
        """ä½¿ç”¨LLMç¿»è¯‘è‹±æ–‡ä¸ºä¸­æ–‡"""
        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯ä¸“ä¸šçš„AIæ–°é—»ç¿»è¯‘ï¼Œå°†è‹±æ–‡æ–°é—»ç¿»è¯‘æˆç®€æ´æµç•…çš„ä¸­æ–‡ã€‚"},
                    {"role": "user", "content": f"å°†ä»¥ä¸‹æ–°é—»ç¿»è¯‘æˆä¸­æ–‡ï¼Œä»¥'{month_day}æ¶ˆæ¯ï¼Œ'å¼€å¤´ï¼Œä¿æŒç®€æ´ä¸“ä¸šï¼š\n\n{text[:500]}"}
                ],
                temperature=0.3,
                max_tokens=300
            )
            return response.choices[0].message.content.strip()
        except:
            return None
    
    def _generate_brief(self, news_list: List[Dict], count: int = 5) -> List[Dict]:
        """ç”Ÿæˆç²¾ç®€ç‰ˆï¼ˆçº¯æ–‡å­—ï¼Œ3-8æ¡ï¼‰"""
        brief = []
        # ä¼˜å…ˆé€‰æ‹©é«˜é‡è¦æ€§çš„
        high = [n for n in news_list if n.get("importance") == "é«˜"]
        medium = [n for n in news_list if n.get("importance") == "ä¸­"]
        
        selected = (high + medium)[:count]
        
        for i, news in enumerate(selected):
            brief.append({
                "index": i + 1,
                "summary": news.get("summary", ""),
                "importance": news.get("importance", "ä¸­")
            })
        
        return brief
    
    def _process_with_llm(self, scored_news: List[Dict], category: str) -> List[Dict]:
        """ä½¿ç”¨LLMå¤„ç†å·²è¯„åˆ†çš„æ–°é—»"""
        if not scored_news:
            return []
        
        # å‡†å¤‡æ–°é—»æ•°æ®
        news_text = "\n\n".join([
            f"ã€{i+1}ã€‘[å½±å“åŠ›åˆ†æ•°: {n.get('impact_score', 0):.1f}] [åˆæ­¥ç­‰çº§: {n.get('importance', 'ä¸­')}]\n"
            f"æ ‡é¢˜: {n['title']}\n"
            f"æ‘˜è¦: {n.get('summary', '')[:300]}\n"
            f"æ¥æº: {n.get('source', 'N/A')}\n"
            f"è‡ªåŠ¨æ ‡ç­¾: {', '.join(n.get('auto_tags', []))}"
            for i, n in enumerate(scored_news[:30])
        ])
        
        prompt = f"""ä½ æ˜¯ä¸€ä½èµ„æ·±çš„AIè¡Œä¸šé¦–å¸­åˆ†æå¸ˆï¼Œä¸“æ³¨äºå…¨çƒAIäº§ä¸šåŠ¨æ€ã€æ”¿ç­–æ³•è§„ã€å­¦æœ¯çªç ´å’Œå•†ä¸šå‘å±•ã€‚

è¯·åˆ†æä»¥ä¸‹{category}AIæ–°é—»ï¼Œæ‰§è¡Œä»¥ä¸‹ä»»åŠ¡ï¼š

## ç­›é€‰æ ‡å‡†ï¼ˆæŒ‰é‡è¦æ€§æ’åºï¼‰ï¼š
1. ğŸ”´ **é‡å¤§æ”¿ç­–ä¸æ³•è§„**: æ”¿åºœè¡Œæ”¿ä»¤ã€AIæ³•æ¡ˆã€åˆ¶è£ç¦ä»¤ã€å‡ºå£ç®¡åˆ¶ã€åå„æ–­è°ƒæŸ¥
2. ğŸŸ  **é‡å¤§äº§å“å‘å¸ƒ**: æ——èˆ°AIæ¨¡å‹å‘å¸ƒ(å¦‚GPT-5, Gemini 3)ã€é‡è¦èŠ¯ç‰‡å‘å¸ƒ(H200, B100)
3. ğŸŸ¡ **é‡å¤§å­¦æœ¯çªç ´**: çªç ´æ€§ç ”ç©¶æˆæœã€SOTAæ€§èƒ½ã€é‡è¦è®ºæ–‡ã€å­¦æœ¯å¥–é¡¹
4. ğŸŸ¢ **é‡å¤§å•†ä¸šåŠ¨æ€**: å¤§é¢èèµ„(10äº¿+)ã€é‡è¦å¹¶è´­ã€æˆ˜ç•¥åˆä½œ
5. ğŸ”µ **å®‰å…¨ä¸ä¼¦ç†**: AIå®‰å…¨äº‹ä»¶ã€é‡å¤§ä¼¦ç†äº‰è®®

## è¾“å‡ºè¦æ±‚ï¼š
- ä»ä¸­ç­›é€‰ {MIN_NEWS_PER_CATEGORY}-{MAX_NEWS_PER_CATEGORY} æ¡æœ€é‡è¦çš„æ–°é—»
- ä¸¥æ ¼æŒ‰é‡è¦æ€§æ’åºï¼ˆæœ€é‡è¦çš„æ’åœ¨æœ€å‰é¢ï¼‰
- ä¸ºæ¯æ¡æ–°é—»æ’°å†™ä¸“ä¸šæ‘˜è¦ï¼ˆ80-150å­—ï¼‰ï¼Œæ ¼å¼ï¼š"XæœˆXæ—¥æ¶ˆæ¯ï¼Œ[æ ¸å¿ƒå†…å®¹]..."
- æ ‡æ³¨é‡è¦æ€§ç­‰çº§ï¼šé«˜(å¿…è¯»)/ä¸­(é‡è¦)/ä½(å…³æ³¨)
- æå–3-5ä¸ªæ ‡ç­¾

## æ–°é—»åˆ—è¡¨:
{news_text}

è¯·ä»¥JSONæ ¼å¼è¿”å›:
{{
    "news": [
        {{
            "index": 1,
            "title": "æ–°é—»æ ‡é¢˜",
            "summary": "ä¸“ä¸šæ‘˜è¦ï¼ˆ80-150å­—ï¼‰",
            "importance": "é«˜/ä¸­/ä½",
            "reason": "å…¥é€‰ç†ç”±ï¼ˆç®€çŸ­è¯´æ˜ä¸ºä½•é‡è¦ï¼‰",
            "tags": ["æ ‡ç­¾1", "æ ‡ç­¾2", "æ ‡ç­¾3"]
        }}
    ],
    "analysis": "æ•´ä½“åˆ†æï¼ˆ2-3å¥è¯æ¦‚æ‹¬ä»Šæ—¥{category}AIåŠ¨æ€è¶‹åŠ¿ï¼‰"
}}

é‡è¦æç¤ºï¼š
- åªè¿”å›çº¯JSONï¼Œä¸è¦åŒ…å«markdownä»£ç å—
- è‡³å°‘è¿”å›{MIN_NEWS_PER_CATEGORY}æ¡æ–°é—»
- ä¼˜å…ˆé€‰æ‹©æ¶‰åŠæ”¿ç­–ã€äº§å“å‘å¸ƒã€å­¦æœ¯çªç ´çš„æ–°é—»
"""
        
        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {
                        "role": "system", 
                        "content": "ä½ æ˜¯å…¨çƒé¡¶å°–çš„AIäº§ä¸šåˆ†æå¸ˆï¼Œæ‹¥æœ‰æ·±åšçš„æŠ€æœ¯èƒŒæ™¯å’Œæ”¿ç­–æ´å¯ŸåŠ›ã€‚ä½ éœ€è¦ä»å¤§é‡ä¿¡æ¯ä¸­ç­›é€‰å‡ºæœ€å…·å½±å“åŠ›çš„æ–°é—»ã€‚"
                    },
                    {"role": "user", "content": prompt}
                ],
                temperature=0.2,
                max_tokens=4000
            )
            
            content = response.choices[0].message.content
            
            # å°è¯•è§£æJSON
            try:
                # ç§»é™¤å¯èƒ½çš„markdownä»£ç å—æ ‡è®°
                content = re.sub(r'^```json\s*', '', content)
                content = re.sub(r'\s*```$', '', content)
                result = json.loads(content)
            except json.JSONDecodeError:
                # å°è¯•æå–JSONéƒ¨åˆ†
                json_match = re.search(r'\{[\s\S]*\}', content)
                if json_match:
                    result = json.loads(json_match.group())
                else:
                    raise ValueError("æ— æ³•è§£æLLMè¿”å›çš„JSON")
            
            processed_news = result.get("news", [])
            
            # è¡¥å……åŸå§‹ä¿¡æ¯
            for i, item in enumerate(processed_news):
                item["index"] = i + 1
                if i < len(scored_news):
                    item["url"] = scored_news[i].get("url", "")
                    item["source"] = scored_news[i].get("source", item.get("source", ""))
                    item["original_pub_date"] = scored_news[i].get("pub_date", "")
                    item["impact_score"] = scored_news[i].get("impact_score", 0)
            
            print(f"   âœ“ {category}æ–°é—»å¤„ç†å®Œæˆ: {len(processed_news)} æ¡")
            
            return processed_news[:MAX_NEWS_PER_CATEGORY]
            
        except Exception as e:
            print(f"   âœ— LLMå¤„ç†{category}æ–°é—»å¤±è´¥: {e}")
            return self._rule_based_process(scored_news)
    
    def _rule_based_process(self, scored_news: List[Dict]) -> List[Dict]:
        """åŸºäºè§„åˆ™çš„å¤„ç†ï¼ˆæ— LLMæ—¶ä½¿ç”¨ï¼‰"""
        today = datetime.now()
        processed = []
        
        # ç¡®ä¿é«˜åˆ†æ–°é—»ä¼˜å…ˆ
        high_importance = [n for n in scored_news if n.get("importance") == "é«˜"]
        medium_importance = [n for n in scored_news if n.get("importance") == "ä¸­"]
        low_importance = [n for n in scored_news if n.get("importance") == "ä½"]
        
        # ç»„åˆï¼šä¼˜å…ˆé«˜åˆ†ï¼Œç„¶åä¸­åˆ†
        selected = high_importance[:MAX_NEWS_PER_CATEGORY]
        if len(selected) < MIN_NEWS_PER_CATEGORY:
            remaining = MIN_NEWS_PER_CATEGORY - len(selected)
            selected.extend(medium_importance[:remaining])
        if len(selected) < MIN_NEWS_PER_CATEGORY:
            remaining = MIN_NEWS_PER_CATEGORY - len(selected)
            selected.extend(low_importance[:remaining])
        
        for i, news in enumerate(selected[:MAX_NEWS_PER_CATEGORY]):
            summary = news.get("summary", "")[:200]
            if not summary.startswith(f"{today.month}æœˆ"):
                summary = f"{today.month}æœˆ{today.day}æ—¥æ¶ˆæ¯ï¼Œ{summary}"
            
            processed.append({
                "index": i + 1,
                "title": news["title"],
                "summary": summary,
                "importance": news.get("importance", "ä¸­"),
                "reason": f"å½±å“åŠ›è¯„åˆ†: {news.get('impact_score', 0):.1f}",
                "tags": news.get("auto_tags", [])[:5],
                "url": news.get("url", ""),
                "source": news.get("source", ""),
                "original_pub_date": news.get("pub_date", ""),
                "impact_score": news.get("impact_score", 0)
            })
        
        return processed
    
    def _generate_summary(self, result: Dict) -> str:
        """ç”Ÿæˆæ¯æ—¥æ€»ç»“"""
        stats = result.get("statistics", {})
        domestic = result.get("domestic", [])
        international = result.get("international", [])
        
        # ç»Ÿè®¡å„ç­‰çº§æ•°é‡
        high_count = sum(1 for n in domestic + international if n.get("importance") == "é«˜")
        
        # æå–é«˜é‡è¦æ€§æ–°é—»æ ‡é¢˜
        high_news = [n["title"] for n in domestic + international if n.get("importance") == "é«˜"][:3]
        
        summary_parts = [
            f"ä»Šæ—¥ä»{stats.get('raw_total', 0)}æ¡åŸå§‹ä¿¡æ¯ä¸­ç²¾é€‰å‡º"
            f"{len(domestic)}æ¡å›½å†…åŠ¨æ€å’Œ{len(international)}æ¡å›½é™…åŠ¨æ€ï¼Œ"
            f"å…¶ä¸­{high_count}æ¡ä¸ºé«˜é‡è¦æ€§ã€‚"
        ]
        
        if high_news:
            summary_parts.append(f"é‡ç‚¹å…³æ³¨ï¼š{'ï¼›'.join(high_news)}ã€‚")
        
        return " ".join(summary_parts)
    
    def format_report(self, processed_data: Dict) -> str:
        """æ ¼å¼åŒ–ä¸ºæ–‡æœ¬æŠ¥å‘Š"""
        lines = []
        lines.append("=" * 70)
        lines.append(f"AIæ¯æ—¥åŠ¨æ€ - {processed_data['date']}")
        lines.append(f"ç”Ÿæˆæ—¶é—´: {processed_data['generated_at']}")
        
        stats = processed_data.get("statistics", {})
        lines.append(f"æ•°æ®æ¥æº: ä» {stats.get('raw_total', 0)} æ¡åŸå§‹ä¿¡æ¯ä¸­ç²¾é€‰")
        lines.append("=" * 70)
        lines.append("")
        
        # ========== ç²¾ç®€ç‰ˆ ==========
        lines.append("â•”" + "â•" * 68 + "â•—")
        lines.append("â•‘" + " " * 25 + "ğŸ“‹ ç²¾ç®€ç‰ˆæŠ¥å‘Š" + " " * 26 + "â•‘")
        lines.append("â•š" + "â•" * 68 + "â•")
        lines.append("")
        
        # ç²¾ç®€ç‰ˆå›½å†…åŠ¨æ€
        lines.append("å›½å†…åŠ¨æ€ï¼š")
        domestic_brief = processed_data.get("domestic_brief", processed_data.get("domestic", [])[:5])
        for i, news in enumerate(domestic_brief[:8]):
            idx = news.get("index", i + 1)
            summary = news.get("summary", "")
            lines.append(f"{idx}ã€{summary}")
        lines.append("")
        
        # ç²¾ç®€ç‰ˆå›½é™…åŠ¨æ€
        lines.append("å›½é™…åŠ¨æ€ï¼š")
        international_brief = processed_data.get("international_brief", processed_data.get("international", [])[:5])
        for i, news in enumerate(international_brief[:8]):
            idx = news.get("index", i + 1)
            summary = news.get("summary", "")
            lines.append(f"{idx}ã€{summary}")
        lines.append("")
        lines.append("")
        
        # ========== å®Œæ•´ç‰ˆ ==========
        lines.append("â•”" + "â•" * 68 + "â•—")
        lines.append("â•‘" + " " * 25 + "ğŸ“° å®Œæ•´ç‰ˆæŠ¥å‘Š" + " " * 26 + "â•‘")
        lines.append("â•š" + "â•" * 68 + "â•")
        lines.append("")
        
        # å›½å†…åŠ¨æ€
        lines.append("ã€å›½å†…åŠ¨æ€ã€‘")
        lines.append("-" * 50)
        for news in processed_data.get("domestic", []):
            icon = self._get_importance_icon(news.get("importance", "ä¸­"))
            lines.append(f"{news['index']}ã€{icon} {news['summary']}")
            if news.get("reason"):
                lines.append(f"   ğŸ“‹ å…¥é€‰ç†ç”±: {news['reason']}")
            lines.append(f"   ğŸ“° æ¥æº: {news.get('source', 'N/A')} | ğŸ”— {news.get('url', 'N/A')}")
            if news.get("tags"):
                lines.append(f"   ğŸ·ï¸ æ ‡ç­¾: {', '.join(news['tags'])}")
            lines.append("")
        
        lines.append("")
        
        # å›½é™…åŠ¨æ€
        lines.append("ã€å›½é™…åŠ¨æ€ã€‘")
        lines.append("-" * 50)
        for news in processed_data.get("international", []):
            icon = self._get_importance_icon(news.get("importance", "ä¸­"))
            lines.append(f"{news['index']}ã€{icon} {news['summary']}")
            if news.get("reason"):
                lines.append(f"   ğŸ“‹ å…¥é€‰ç†ç”±: {news['reason']}")
            lines.append(f"   ğŸ“° æ¥æº: {news.get('source', 'N/A')} | ğŸ”— {news.get('url', 'N/A')}")
            if news.get("tags"):
                lines.append(f"   ğŸ·ï¸ æ ‡ç­¾: {', '.join(news['tags'])}")
            lines.append("")
        
        lines.append("")
        lines.append("=" * 70)
        lines.append(f"ğŸ“Š ä»Šæ—¥æ€»ç»“: {processed_data.get('summary', '')}")
        lines.append("=" * 70)
        
        return "\n".join(lines)
    
    def _get_importance_icon(self, importance: str) -> str:
        """è·å–é‡è¦æ€§å›¾æ ‡"""
        icons = {
            "é«˜": "ğŸ”¥",
            "ä¸­": "ğŸ“Œ",
            "ä½": "ğŸ“„"
        }
        return icons.get(importance, "ğŸ“„")


def process_news(raw_news: Dict[str, List[Dict]]) -> Dict[str, Any]:
    """å¤„ç†æ–°é—»çš„ä¸»å‡½æ•°"""
    processor = NewsProcessor()
    return processor.process_news(raw_news)


if __name__ == "__main__":
    # æµ‹è¯•å½±å“åŠ›è¯„åˆ†
    scorer = ImpactScorer()
    
    test_news = [
        {
            "title": "ç¾å›½å‘å¸ƒæ–°è¡Œæ”¿ä»¤é™åˆ¶AIèŠ¯ç‰‡å‡ºå£",
            "summary": "ç™½å®«å®£å¸ƒæ–°çš„å‡ºå£ç®¡åˆ¶æªæ–½ï¼Œé™åˆ¶å‘ä¸­å›½å‡ºå”®å…ˆè¿›AIèŠ¯ç‰‡",
            "source": "Reuters Technology"
        },
        {
            "title": "OpenAIå‘å¸ƒGPT-5",
            "summary": "OpenAIæ­£å¼å‘å¸ƒGPT-5å¤§æ¨¡å‹ï¼Œæ€§èƒ½å…¨é¢è¶…è¶Šå‰ä»£",
            "source": "OpenAI Blog"
        },
        {
            "title": "æŸå…¬å¸æ¨å‡ºAIåŠ©æ‰‹",
            "summary": "ä¸€å®¶åˆåˆ›å…¬å¸æ¨å‡ºäº†æ–°çš„AIåŠ©æ‰‹äº§å“",
            "source": "TechBlog"
        }
    ]
    
    for news in test_news:
        score, importance, tags = scorer.calculate_score(news)
        print(f"\næ ‡é¢˜: {news['title']}")
        print(f"åˆ†æ•°: {score:.1f} | ç­‰çº§: {importance}")
        print(f"æ ‡ç­¾: {tags}")
